{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__version__ = 1 + 1e-1 + 1j\n",
    "__author__ = \"Bavon C. K. Chao (赵庆华)\"\n",
    "\n",
    "from functools import partial\n",
    "from json import dumps\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将字典dump成json同时进行格式化\n",
    "json_dumps = partial(dumps,\n",
    "                     ensure_ascii=False,\n",
    "                     indent=4,\n",
    "                     separators=(', ', ': '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHARPEN_KERNEL = np.asarray(((0, -1, 0), (-1, 5, -1), (0, -1, 0)))\n",
    "EMBOSS_KERNEL = np.asarray(((-2, -1, 0), (-1, 1, 1), (0, 1, 2)))\n",
    "EDGE_SCHARR_KERNEL = np.asarray(\n",
    "    ((-3 - 3j, 0 - 10j, 3 - 3j), (-10 + 0j, 0j, 10 + 0j), (-3 + 3j, 10j,\n",
    "                                                           3 + 3j)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def fft(img):\n",
    "    \"\"\"傅利叶变换\"\"\"\n",
    "    freq1 = np.fft.fft2(img)\n",
    "\n",
    "    # NOTE np.vectorize 是构造numpy矩阵的一种方法\n",
    "    print((freq1 == np.vectorize(complex)(freq1.real, freq1.imag)).all())\n",
    "    freq2 = np.fft.fftshift(freq1)\n",
    "    # freq2_low = np.copy(freq2)  # NOTE 用于低通滤波器运算\n",
    "    (w, h) = freq2.shape[:2]\n",
    "    w, h = map(lambda x: int(x / 2), (w, h))\n",
    "    # 高通滤波，下面切片部分越大则影响越大\n",
    "    freq2[w - 10:w + 11, h - 10:h + 11] = 0\n",
    "    # # NOTE 低通滤波\n",
    "    # freq2 -= freq2_low\n",
    "    # FFT频谱图像\n",
    "    spectrum_img = 20 * np.log10(np.abs(freq2 + 1e-2))\n",
    "    # FFT相位图\n",
    "    phase_img = np.angle(freq2)\n",
    "    # 逆FFT重建图像；clip用于限制矩阵中的数的最大和最小值\n",
    "    img_ = np.fft.ifft2(np.fft.ifftshift(freq2)).real\n",
    "    # reduction_img = np.clip(img_, 0, 255)\n",
    "    img_ -= np.min(img_)\n",
    "    reduction_img = img_ / np.abs(np.max(img_)) * 255\n",
    "\n",
    "    plt.subplot(2, 2, 1), plt.imshow(img,\n",
    "                                     cmap=\"gray\"), plt.title(\"Original Image\",\n",
    "                                                             size=20)\n",
    "    plt.subplot(2, 2, 2), plt.imshow(spectrum_img, cmap=\"gray\"), plt.title(\n",
    "        \"FFT Spectrum Magnitude\", size=20)\n",
    "\n",
    "    plt.subplot(2, 2, 3), plt.imshow(phase_img,\n",
    "                                     cmap=\"gray\"), plt.title(\"FFT Phase\",\n",
    "                                                             size=20)\n",
    "\n",
    "    plt.subplot(2, 2,\n",
    "                4), plt.imshow(reduction_img,\n",
    "                               cmap=\"gray\"), plt.title(\"Reconstructed Image\",\n",
    "                                                       size=20)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_derivative(img):\n",
    "    \"\"\"计算图像导数\"\"\"\n",
    "    kernel_x = np.asarray(((-1, 1), ))\n",
    "    kernel_y = np.asarray(((-1, ), (1, )))\n",
    "    img_x = cv2.filter2D(img, cv2.CV_8U, kernel_x)  # 横向偏导\n",
    "    img_y = cv2.filter2D(img, cv2.CV_8U, kernel_y)  # 纵向偏导\n",
    "    img_mag = np.sqrt(img_x**2 + pow(img_y, 2))  # 偏导图像合并\n",
    "    img_dir = np.arctan(img_y / img_x)  # θ\n",
    "    img_dir = np.where(np.isnan(img_dir), 0, img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace(img):\n",
    "    img_lplc = cv2.Laplacian(img, cv2.CV_8U, ksize=3)\n",
    "    # 原始图像加拉普拉斯，得到锐化图像\n",
    "    sharpened_img = np.clip(cv2.addWeighted(img, .8, img_lplc, .8, 0), 0, 255)\n",
    "    display(Image.fromarray(sharpened_img))\n",
    "    \n",
    "    # img_ = img_lplc + img\n",
    "    # img_ -= np.min(img_)\n",
    "    # sharpened_img = img_ / np.abs(np.max(img_)) * 255\n",
    "    # 反锐化\n",
    "    img_delta = np.clip(img - img_lplc, 0, 255)\n",
    "    sharpened_img = np.clip(img + img_delta * 5, 0, 255)\n",
    "    display(Image.fromarray(sharpened_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def py_cpu_nms(dets, thresh):\n",
    "    \"\"\"非最大抑制算法，用于合并部分重合的候选框\"\"\"\n",
    "    x1, y1, x2, y2, scores = dets[:, :5]\n",
    "    \n",
    "    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    order = scores.argsort()[::-1]\n",
    "\n",
    "    keep = []\n",
    "    while order.size > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i)\n",
    "        xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "        yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "        xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "        yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "\n",
    "        w = np.maximum(0.0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0.0, yy2 - yy1 + 1)\n",
    "        inter = w * h\n",
    "        ovr = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "\n",
    "        inds = np.where(ovr <= thresh)[0]\n",
    "        order = order[inds + 1]\n",
    "\n",
    "    return keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"test.jpg\", cv2.IMREAD_COLOR)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img_eq = cv2.equalizeHist(img)  # 直方图均衡化，增加对比度\n",
    "# CLAHE 有限对比适应性直方图均衡化\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "img_clahe = clahe.apply(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "遍历不规则树状数据结构（比如cv2.findContours的返回值）伪代码\n",
    "```python\n",
    "contours, hierarchy = cv2.findContours(img, cv2.RETR_TREE,\n",
    "                                       cv2.CHAIN_APPROX_SIMPLE)\n",
    "def parse_contours_tree(hierarchy, current_node):\n",
    "    for node in current_node.sisters：\n",
    "        # 处理具有同一个父节点的同级别所有节点\n",
    "        if node.is_last_node:\n",
    "            # 如果是最后一层节点，可能有特殊处理\n",
    "        else:\n",
    "            # 如果有子节点，处理当前节点，并处理子节点\n",
    "            for sub_node in node.children:\n",
    "                # 递归处理子节点的子节点\n",
    "                parse_contours_tree(hierarchy, sub_node)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "-1.0\n",
      "0.0\n",
      "0.5\n",
      "-0.0\n",
      "-1.0\n"
     ]
    }
   ],
   "source": [
    "# 凸包算法，将点集合顺时针排序\n",
    "points = cv2.convexHull(np.asarray(((1, 1), (1, 3), (3, 1), (3, 3))), clockwise=True)\n",
    "\n",
    "# 判断一个点和一个点集合的位置关系，第三个参数表示是否计算点与点集合的距离\n",
    "print(cv2.pointPolygonTest(points, (2.5, 2), False))\n",
    "print(cv2.pointPolygonTest(points, (0, 2), False))\n",
    "print(cv2.pointPolygonTest(points, (1, 2), False))\n",
    "\n",
    "print(cv2.pointPolygonTest(points, (2.5, 2), True))\n",
    "print(cv2.pointPolygonTest(points, (1, 2), True))\n",
    "print(cv2.pointPolygonTest(points, (0, 2), True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.arctan2 函数可以计算大于 180° 的角度"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
